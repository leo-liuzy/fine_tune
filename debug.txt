lr: 0.0001 	 num_train_epochs: 20
Namespace(adam_epsilon=1e-08, apply_adapter=True, bottleneck_size=64, cache_dir='', config_name='/home/leo/fine_tune/cache/bert-base-uncased-config.json', do_eval=True, do_lower_case=True, do_train=True, doc_stride=128, dropout=0.2, elmo_style=False, eval_all_checkpoints=False, evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, init_scale=0.001, learning_rate=0.0001, local_rank=-1, logging_dir='/home/leo/fine_tune/logs', logging_steps=50, max_answer_length=30, max_grad_norm=1.0, max_query_length=64, max_seq_length=384, max_steps=-1, model_name_or_path='/home/leo/fine_tune/cache/bert-base-uncased-pytorch_model.bin', model_type='bert', n_best_size=20, no_cuda=False, null_score_diff_threshold=0.0, num_train_epochs=20, output_dir='/home/leo/fine_tune/out/lr0.0001.unfreeze_top_0_bert_layer.epoch20.bs12.adapter64', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=12, per_gpu_train_batch_size=12, predict_file='/home/leo/fine_tune/data/squad1_1/dev-v1.1.json', save_steps=5540, seed=42, server_ip='', server_port='', tokenizer_name='/home/leo/fine_tune/cache/bert-base-uncased-vocab.txt', top_layer='linear', train_file='/home/leo/fine_tune/data/squad1_1/train-v1.1.json', unfreeze_top_k_bert_layer=0, verbose_logging=False, version_2_with_negative=False, warmup_steps=0, weight_decay=0.0)
lr: 3e-05 	 num_train_epochs: 3
Namespace(adam_epsilon=1e-08, apply_adapter=True, bottleneck_size=64, cache_dir='', config_name='/home/leo/fine_tune/cache/bert-base-uncased-config.json', do_eval=True, do_lower_case=True, do_train=True, doc_stride=128, dropout=0.2, elmo_style=False, eval_all_checkpoints=False, evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, init_scale=0.001, learning_rate=3e-05, local_rank=-1, logging_dir='/home/leo/fine_tune/logs', logging_steps=50, max_answer_length=30, max_grad_norm=1.0, max_query_length=64, max_seq_length=384, max_steps=-1, model_name_or_path='/home/leo/fine_tune/cache/bert-base-uncased-pytorch_model.bin', model_type='bert', n_best_size=20, no_cuda=False, null_score_diff_threshold=0.0, num_train_epochs=3, output_dir='/home/leo/fine_tune/out/lr3e-05.unfreeze_top_0_bert_layer.epoch3.bs12.adapter64', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=12, per_gpu_train_batch_size=12, predict_file='/home/leo/fine_tune/data/squad1_1/dev-v1.1.json', save_steps=5540, seed=42, server_ip='', server_port='', tokenizer_name='/home/leo/fine_tune/cache/bert-base-uncased-vocab.txt', top_layer='linear', train_file='/home/leo/fine_tune/data/squad1_1/train-v1.1.json', unfreeze_top_k_bert_layer=0, verbose_logging=False, version_2_with_negative=False, warmup_steps=0, weight_decay=0.0)
lr: 0.0003 	 num_train_epochs: 10
Namespace(adam_epsilon=1e-08, apply_adapter=True, bottleneck_size=64, cache_dir='', config_name='/home/leo/fine_tune/cache/bert-base-uncased-config.json', do_eval=True, do_lower_case=True, do_train=True, doc_stride=128, dropout=0.2, elmo_style=False, eval_all_checkpoints=False, evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, init_scale=0.001, learning_rate=0.0003, local_rank=-1, logging_dir='/home/leo/fine_tune/logs', logging_steps=50, max_answer_length=30, max_grad_norm=1.0, max_query_length=64, max_seq_length=384, max_steps=-1, model_name_or_path='/home/leo/fine_tune/cache/bert-base-uncased-pytorch_model.bin', model_type='bert', n_best_size=20, no_cuda=False, null_score_diff_threshold=0.0, num_train_epochs=10, output_dir='/home/leo/fine_tune/out/lr0.0003.unfreeze_top_0_bert_layer.epoch10.bs12.adapter64', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=12, per_gpu_train_batch_size=12, predict_file='/home/leo/fine_tune/data/squad1_1/dev-v1.1.json', save_steps=5540, seed=42, server_ip='', server_port='', tokenizer_name='/home/leo/fine_tune/cache/bert-base-uncased-vocab.txt', top_layer='linear', train_file='/home/leo/fine_tune/data/squad1_1/train-v1.1.json', unfreeze_top_k_bert_layer=0, verbose_logging=False, version_2_with_negative=False, warmup_steps=0, weight_decay=0.0)
lr: 0.0003 	 num_train_epochs: 20
Namespace(adam_epsilon=1e-08, apply_adapter=True, bottleneck_size=64, cache_dir='', config_name='/home/leo/fine_tune/cache/bert-base-uncased-config.json', do_eval=True, do_lower_case=True, do_train=True, doc_stride=128, dropout=0.2, elmo_style=False, eval_all_checkpoints=False, evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, init_scale=0.001, learning_rate=0.0003, local_rank=-1, logging_dir='/home/leo/fine_tune/logs', logging_steps=50, max_answer_length=30, max_grad_norm=1.0, max_query_length=64, max_seq_length=384, max_steps=-1, model_name_or_path='/home/leo/fine_tune/cache/bert-base-uncased-pytorch_model.bin', model_type='bert', n_best_size=20, no_cuda=False, null_score_diff_threshold=0.0, num_train_epochs=20, output_dir='/home/leo/fine_tune/out/lr0.0003.unfreeze_top_0_bert_layer.epoch20.bs12.adapter64', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=12, per_gpu_train_batch_size=12, predict_file='/home/leo/fine_tune/data/squad1_1/dev-v1.1.json', save_steps=5540, seed=42, server_ip='', server_port='', tokenizer_name='/home/leo/fine_tune/cache/bert-base-uncased-vocab.txt', top_layer='linear', train_file='/home/leo/fine_tune/data/squad1_1/train-v1.1.json', unfreeze_top_k_bert_layer=0, verbose_logging=False, version_2_with_negative=False, warmup_steps=0, weight_decay=0.0)
lr: 0.0003 	 num_train_epochs: 20
Namespace(adam_epsilon=1e-08, apply_adapter=True, bottleneck_size=64, cache_dir='', config_name='/home/leo/fine_tune/cache/bert-base-uncased-config.json', do_eval=True, do_lower_case=True, do_train=True, doc_stride=128, dropout=0.2, elmo_style=False, eval_all_checkpoints=False, evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, init_scale=0.001, learning_rate=0.0003, local_rank=-1, logging_dir='/home/leo/fine_tune/logs', logging_steps=50, max_answer_length=30, max_grad_norm=1.0, max_query_length=64, max_seq_length=384, max_steps=-1, model_name_or_path='/home/leo/fine_tune/cache/bert-base-uncased-pytorch_model.bin', model_type='bert', n_best_size=20, no_cuda=False, null_score_diff_threshold=0.0, num_train_epochs=20, output_dir='/home/leo/fine_tune/out/lr0.0003.unfreeze_top_0_bert_layer.epoch20.bs12.adapter64', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=12, per_gpu_train_batch_size=12, predict_file='/home/leo/fine_tune/data/squad1_1/dev-v1.1.json', save_steps=5540, seed=42, server_ip='', server_port='', tokenizer_name='/home/leo/fine_tune/cache/bert-base-uncased-vocab.txt', top_layer='linear', train_file='/home/leo/fine_tune/data/squad1_1/train-v1.1.json', unfreeze_top_k_bert_layer=0, verbose_logging=False, version_2_with_negative=False, warmup_steps=0, weight_decay=0.0)
